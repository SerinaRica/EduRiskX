# src/flogic_reasoner_optimized.py (ä¿®å¤ç‰ˆæœ¬)

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Set, Tuple
from .flogic_parser import FLogicParser

class OptimizedFLogicReasoner:
    """
    Optimized F-Logic Reasoning Engine
    Directly uses F-Logic rules from your JSON
    """
    
    def __init__(self, rules_file: str = "outputs/rules/enhanced_rules.json"):
        self.rules = self._load_rules(rules_file)
        self.parsed_rules = FLogicParser.extract_flogic_rules(self.rules)
        self.feature_index = self._build_feature_index()
        self.rule_by_id = {rule['rule_id']: rule for rule in self.parsed_rules}
        
        print(f"âœ“ Loaded {len(self.parsed_rules)} F-Logic rules")
        print(f"âœ“ Indexed {len(self.feature_index)} features")
    
    def _load_rules(self, file_path: str) -> List[Dict]:
        """Load JSON rules"""
        import json
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _build_feature_index(self) -> Dict[str, List[str]]:
        """Build feature index for faster reasoning - returns list of rule_ids instead of rule objects"""
        feature_index = {}
        
        for rule in self.parsed_rules:
            rule_id = rule['rule_id']
            conditions = rule['parsed']['conditions']
            
            for cond in conditions:
                if cond['type'] == 'comparison':
                    feature = cond['feature']
                    if feature not in feature_index:
                        feature_index[feature] = []
                    if rule_id not in feature_index[feature]:
                        feature_index[feature].append(rule_id)
                elif cond['type'] == 'range':
                    feature = cond['feature']
                    if feature not in feature_index:
                        feature_index[feature] = []
                    if rule_id not in feature_index[feature]:
                        feature_index[feature].append(rule_id)
        
        return feature_index
    
    def _check_condition(self, condition: Dict, student_data: Dict) -> bool:
        """æ£€æŸ¥å•ä¸ªæ¡ä»¶æ˜¯å¦æ»¡è¶³"""
        cond_type = condition['type']
        
        if cond_type == 'comparison':
            return self._check_comparison(condition, student_data)
        elif cond_type == 'range':
            return self._check_range(condition, student_data)
        elif cond_type == 'theory_alignment':
            # ç†è®ºå¯¹é½æ¡ä»¶åœ¨è§„åˆ™å¤´éƒ¨å·²å¤„ç†ï¼Œè¿™é‡Œé»˜è®¤é€šè¿‡
            return True
        elif cond_type == 'existence':
            # å¦‚ Student(S)ï¼Œé»˜è®¤é€šè¿‡
            return True
        else:
            # åŸå§‹æ¡ä»¶ï¼Œå°è¯•ç›´æ¥è¯„ä¼°
            return self._evaluate_raw_condition(condition, student_data)
    
    def _check_comparison(self, condition: Dict, student_data: Dict) -> bool:
        """æ£€æŸ¥æ¯”è¾ƒæ¡ä»¶"""
        feature = condition['feature']
        operator = condition['operator']
        value = condition['value']
        
        if feature not in student_data:
            return False
        
        student_value = student_data[feature]
        
        # å¤„ç†å­—ç¬¦ä¸²å’Œæ•°å€¼æ¯”è¾ƒ
        if isinstance(value, str) and value.replace('.', '').replace('-', '').isdigit():
            value = float(value) if '.' in value else int(value)
        
        # æ ‡å‡†åŒ–æ“ä½œç¬¦
        operator_map = {
            'â‰¥': '>=',
            'â‰¤': '<=',
            'â‰ ': '!=',
            '=': '==',
            '>=': '>=',
            '<=': '<=',
            '!=': '!=',
            '==': '==',
            '>': '>',
            '<': '<'
        }
        
        op = operator_map.get(operator, operator)
        
        try:
            if op == '>=':
                return student_value >= value
            elif op == '<=':
                return student_value <= value
            elif op == '>':
                return student_value > value
            elif op == '<':
                return student_value < value
            elif op in ['==', '=']:
                return student_value == value
            elif op == '!=':
                return student_value != value
        except TypeError as e:
            # å¦‚æœç±»å‹ä¸åŒ¹é…ï¼Œå°è¯•è½¬æ¢
            try:
                student_value = float(student_value)
                if isinstance(value, str):
                    value = float(value)
                return self._check_comparison({
                    'feature': feature,
                    'operator': op,
                    'value': value
                }, {feature: student_value})
            except:
                return False
        
        return False
    
    def _check_range(self, condition: Dict, student_data: Dict) -> bool:
        """æ£€æŸ¥åŒºé—´æ¡ä»¶"""
        feature = condition['feature']
        lower = condition['lower']
        upper = condition['upper']
        
        if feature not in student_data:
            return False
        
        student_value = student_data[feature]
        return lower <= student_value <= upper
    
    def _evaluate_raw_condition(self, condition: Dict, student_data: Dict) -> bool:
        """è¯„ä¼°åŸå§‹æ¡ä»¶å­—ç¬¦ä¸² - ç®€åŒ–å®ç°"""
        cond_str = condition['condition']
        
        # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
        if 'week âˆˆ' in cond_str:
            # å°è¯•è§£æåŒºé—´
            try:
                import re
                match = re.search(r'\[([\d.]+),\s*([\d.]+)\]', cond_str)
                if match:
                    lower, upper = float(match.group(1)), float(match.group(2))
                    if 'week' in student_data:
                        return lower <= student_data['week'] <= upper
            except:
                pass
        elif 'â‰¥' in cond_str or '<=' in cond_str or '==' in cond_str:
            # å°è¯•è§£ææ¯”è¾ƒ
            try:
                parts = cond_str.replace('â‰¥', '>=').replace('â‰¤', '<=').split()
                if len(parts) >= 3:
                    feature = parts[0]
                    operator = parts[1]
                    value_str = parts[2]
                    
                    if feature in student_data:
                        value = float(value_str) if '.' in value_str else int(value_str)
                        return self._check_comparison({
                            'feature': feature,
                            'operator': operator,
                            'value': value
                        }, student_data)
            except:
                pass
        
        return False
    
    def evaluate_student(self, student_data: Dict) -> Dict:
        """
        è¯„ä¼°å•ä¸ªå­¦ç”Ÿ
        è¿”å›: è§¦å‘çš„è§„åˆ™å’Œé£é™©è¯„ä¼°
        """
        student_id = student_data.get('id_student', 'unknown')
        
        # åªæ£€æŸ¥ç›¸å…³çš„è§„åˆ™ - ä¿®å¤è¿™é‡Œ
        relevant_features = set(student_data.keys()) & set(self.feature_index.keys())
        candidate_rule_ids = set()
        
        for feature in relevant_features:
            for rule_id in self.feature_index.get(feature, []):
                candidate_rule_ids.add(rule_id)
        
        triggered_rules = []
        
        # æ£€æŸ¥æ¯ä¸ªå€™é€‰è§„åˆ™
        for rule_id in candidate_rule_ids:
            rule = self.rule_by_id.get(rule_id)
            if rule and self._check_rule(rule, student_data):
                triggered_rules.append({
                    'rule_id': rule['rule_id'],
                    'name': rule['name'],
                    'theory': rule['theory'],
                    'confidence': rule['confidence'],
                    'theory_score': rule['theory_score'],
                    'flogic_rule': rule['flogic_string']
                })
        
        # è¯æ®åˆæˆ
        overall_risk = self._synthesize_evidence(triggered_rules)
        
        # ç”Ÿæˆè§£é‡Š
        explanation = self._generate_explanation(triggered_rules, overall_risk)
        
        return {
            'student_id': student_id,
            'triggered_rules': triggered_rules,
            'triggered_count': len(triggered_rules),
            'overall_risk': overall_risk,
            'explanation': explanation,
            'recommended_interventions': self._suggest_interventions(triggered_rules, overall_risk)
        }
    
    def _check_rule(self, rule: Dict, student_data: Dict) -> bool:
        """æ£€æŸ¥è§„åˆ™çš„æ‰€æœ‰æ¡ä»¶æ˜¯å¦éƒ½æ»¡è¶³"""
        conditions = rule['parsed']['conditions']
        
        for condition in conditions:
            if not self._check_condition(condition, student_data):
                return False
        
        return True
    
        # src/flogic_reasoner_optimized.py (æ›´æ–°_synthesize_evidenceæ–¹æ³•)

    def _synthesize_evidence(self, triggered_rules: List) -> Dict:
        """
        åˆæˆè¯æ® - æ ¹æ®ä½ çš„è§„åˆ™è°ƒæ•´é˜ˆå€¼
        """
        if not triggered_rules:
            return {
                'level': 'No Risk',
                'belief': 0.0,
                'confidence': 0.0,
                'theory_distribution': {}
            }
        
        # æŒ‰ç†è®ºåˆ†ç»„
        theory_scores = {}
        for rule in triggered_rules:
            theory = rule['theory']
            if theory not in theory_scores:
                theory_scores[theory] = []
            theory_scores[theory].append(rule['confidence'])
        
        # è®¡ç®—æ¯ä¸ªç†è®ºçš„å¹³å‡ç½®ä¿¡åº¦
        theory_avg = {}
        for theory, scores in theory_scores.items():
            theory_avg[theory] = np.mean(scores)
        
        # ç¡®å®šä¸»å¯¼ç†è®º
        if theory_avg:
            dominant_theory = max(theory_avg.items(), key=lambda x: x[1])[0]
            dominant_score = theory_avg[dominant_theory]
        else:
            dominant_theory = None
            dominant_score = 0.0
        
        # ä½¿ç”¨åŠ æƒç½®ä¿¡åº¦ï¼ˆè€ƒè™‘è§„åˆ™æ•°é‡å’Œç†è®ºåˆ†æ•°ï¼Œé™ä½æ”¾å¤§ç³»æ•°ä»¥é¿å…è¿‡åº¦æ­£ä¾‹ï¼‰
        weighted_confidence = dominant_score * (1 + 0.02 * len(triggered_rules))
        weighted_confidence = min(weighted_confidence, 1.0)  # ä¸Šé™ä¸º1.0
        
        # æ›´ä¿å®ˆçš„é£é™©åˆ†çº§é˜ˆå€¼ï¼ˆå‡å°‘è¯¯æŠ¥ï¼‰
        if weighted_confidence >= 0.65:
            risk_level = 'High'
        elif weighted_confidence >= 0.55:
            risk_level = 'Medium'
        elif weighted_confidence >= 0.45:
            risk_level = 'Low'
        else:
            risk_level = 'No Risk'
        
        return {
            'level': risk_level,
            'belief': dominant_score,
            'weighted_confidence': weighted_confidence,
            'confidence': np.mean([r['confidence'] for r in triggered_rules]),
            'dominant_theory': dominant_theory,
            'theory_distribution': theory_avg,
            'rule_count': len(triggered_rules),
            'triggered_rule_ids': [r['rule_id'] for r in triggered_rules]
        }
    def _generate_explanation(self, triggered_rules: List, overall_risk: Dict) -> str:
        """ç”Ÿæˆå¯è§£é‡Šçš„è¾“å‡º"""
        if not triggered_rules:
            return "æœªè§¦å‘ä»»ä½•é£é™©è§„åˆ™ï¼Œå­¦ç”Ÿå­¦ä¹ è¡Œä¸ºæ­£å¸¸ã€‚"
        
        explanation = []
        explanation.append(f"ğŸ” é£é™©è¯„ä¼°: {overall_risk['level']} é£é™©")
        explanation.append(f"   ç½®ä¿¡åº¦: {overall_risk['belief']:.1%}")
        explanation.append(f"   ä¸»å¯¼ç†è®º: {overall_risk.get('dominant_theory', 'N/A')}")
        explanation.append("")
        explanation.append("ğŸ“‹ è§¦å‘çš„é£é™©è§„åˆ™:")
        
        for i, rule in enumerate(triggered_rules[:5], 1):  # æœ€å¤šæ˜¾ç¤º5æ¡
            explanation.append(f"   {i}. [{rule['rule_id']}] {rule['name']}")
            explanation.append(f"      ç†è®º: {rule['theory']} (å¯¹é½åº¦: {rule['theory_score']:.3f})")
            explanation.append(f"      ç½®ä¿¡åº¦: {rule['confidence']:.1%}")
        
        if len(triggered_rules) > 5:
            explanation.append(f"   ... ä»¥åŠå…¶ä»– {len(triggered_rules) - 5} æ¡è§„åˆ™")
        
        explanation.append("")
        explanation.append("ğŸ¯ é£é™©æŒ‡ç¤ºå™¨:")
        
        # æŒ‰ç†è®ºåˆ†ç»„æ˜¾ç¤º
        theory_groups = {}
        for rule in triggered_rules:
            theory = rule['theory']
            if theory not in theory_groups:
                theory_groups[theory] = []
            theory_groups[theory].append(rule)
        
        for theory, rules in theory_groups.items():
            explanation.append(f"  â€¢ {theory} ç†è®ºæŒ‡ç¤ºå™¨ ({len(rules)} æ¡è§„åˆ™):")
            for rule in rules[:2]:  # æ¯ä¸ªç†è®ºæœ€å¤šæ˜¾ç¤º2æ¡
                rule_data = self.rule_by_id.get(rule['rule_id'])
                if rule_data:
                    conditions = []
                    for cond in rule_data['parsed']['conditions']:
                        if cond['type'] == 'comparison':
                            conditions.append(f"{cond['feature']} {cond['operator']} {cond['value']}")
                        elif cond['type'] == 'range':
                            conditions.append(f"{cond['feature']} âˆˆ [{cond['lower']}, {cond['upper']}]")
                    
                    if conditions:
                        explanation.append(f"    - {', '.join(conditions)}")
        
        return "\n".join(explanation)
    
    def _suggest_interventions(self, triggered_rules: List, overall_risk: Dict) -> List[str]:
        """æ ¹æ®è§¦å‘çš„è§„åˆ™å’Œå»ºè®®å¹²é¢„"""
        interventions = []
        
        if overall_risk['level'] == 'High':
            interventions.append("ğŸš¨ éœ€è¦ç«‹å³å¹²é¢„")
            interventions.append("â€¢ å®‰æ’ä¸€å¯¹ä¸€å­¦æœ¯è¾…å¯¼")
            interventions.append("â€¢ è”ç³»å­¦ç”Ÿäº†è§£å­¦ä¹ å›°éš¾")
        
        # æ ¹æ®ç†è®ºå»ºè®®å¹²é¢„
        theory_interventions = {
            'Engagement': [
                "â€¢ å¢åŠ å­¦ä¹ äº’åŠ¨æ´»åŠ¨",
                "â€¢ è®¾ç½®æ¯å‘¨å­¦ä¹ ç›®æ ‡",
                "â€¢ æä¾›å­¦ä¹ è¿›åº¦åé¦ˆ"
            ],
            'SelfEfficacy': [
                "â€¢ æä¾›æˆåŠŸæ¡ˆä¾‹åˆ†äº«",
                "â€¢ åˆ†è§£å¤æ‚ä»»åŠ¡ä¸ºå°æ­¥éª¤",
                "â€¢ ç»™äºˆåŠæ—¶ç§¯æåé¦ˆ"
            ],
            'StudentIntegration': [
                "â€¢ é‚€è¯·åŠ å…¥å­¦ä¹ å°ç»„",
                "â€¢ é¼“åŠ±å‚ä¸è®ºå›è®¨è®º",
                "â€¢ ç»„ç»‡çº¿ä¸Šç¤¾äº¤æ´»åŠ¨"
            ]
        }
        
        # æ·»åŠ ç†è®ºç‰¹å®šçš„å¹²é¢„
        for rule in triggered_rules:
            theory = rule['theory']
            if theory in theory_interventions:
                for intervention in theory_interventions[theory]:
                    if intervention not in interventions:
                        interventions.append(intervention)
        
        return interventions[:6]  # æœ€å¤šè¿”å›6æ¡å»ºè®®
    
    def batch_evaluate(self, student_data_list: List[Dict]) -> Tuple[pd.DataFrame, List[Dict]]:
        """æ‰¹é‡è¯„ä¼°å­¦ç”Ÿ"""
        results = []
        
        for student_data in student_data_list:
            result = self.evaluate_student(student_data)
            results.append(result)
        
        # è½¬æ¢ä¸ºDataFrame
        df_results = pd.DataFrame([{
            'student_id': r['student_id'],
            'risk_level': r['overall_risk']['level'],
            'belief': r['overall_risk']['belief'],
            'confidence': r['overall_risk']['confidence'],
            'triggered_rules': len(r['triggered_rules']),
            'dominant_theory': r['overall_risk'].get('dominant_theory', 'None')
        } for r in results])
        
        return df_results, results
    
    def save_knowledge_base(self, output_dir: str = "outputs/knowledge_base"):
        """ä¿å­˜çŸ¥è¯†åº“æ–‡ä»¶"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ä¿å­˜å®Œæ•´çš„F-LogicçŸ¥è¯†åº“
        flogic_file = os.path.join(output_dir, "complete_knowledge_base.flogic")
        with open(flogic_file, 'w', encoding='utf-8') as f:
            f.write("% Complete F-Logic Knowledge Base\n")
            f.write("% Generated from enhanced_rules.json\n\n")
            
            f.write("% Type Declarations\n")
            f.write("Student :: Object.\n")
            f.write("Rule :: Object.\n")
            f.write("Theory :: Object.\n\n")
            
            f.write("% All F-Logic Rules\n")
            for rule in self.parsed_rules:
                f.write(rule['flogic_string'])
                f.write("\n\n")
        
        print(f"âœ“ çŸ¥è¯†åº“å·²ä¿å­˜: {flogic_file}")
        
        # 2. ä¿å­˜è§„åˆ™ç»Ÿè®¡
        stats_file = os.path.join(output_dir, "rule_statistics.json")
        stats = {
            'total_rules': len(self.parsed_rules),
            'rules_by_type': {},
            'rules_by_theory': {},
            'avg_confidence': float(np.mean([r['confidence'] for r in self.parsed_rules])),
            'avg_theory_score': float(np.mean([r['theory_score'] for r in self.parsed_rules]))
        }
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        for rule in self.parsed_rules:
            rule_type = rule['rule_type']
            stats['rules_by_type'][rule_type] = stats['rules_by_type'].get(rule_type, 0) + 1
            
            theory = rule['theory']
            stats['rules_by_theory'][theory] = stats['rules_by_theory'].get(theory, 0) + 1
        
        import json
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ è§„åˆ™ç»Ÿè®¡å·²ä¿å­˜: {stats_file}")
        
        return flogic_file, stats_file
